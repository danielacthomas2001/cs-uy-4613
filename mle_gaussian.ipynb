{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielacthomas2001/cs-uy-4613/blob/main/mle_gaussian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDJfXpS6ORSs"
      },
      "source": [
        "# Gaussian Maximum Likelihood\n",
        "\n",
        "##  MLE of a  Gaussian $p_{model}(x|w)$\n",
        "\n",
        "You are given an array of data points called `data`. Your course site plots the negative log-likelihood  function for several candidate hypotheses. Estimate the parameters of the Gaussian $p_{model}$ by  coding an implementation that estimates its optimal parameters (15 points) and explaining what it does (10 points). You are free to use any Gradient-based optimization method you like.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sEdRJldORSt",
        "outputId": "db4a51a1-7112-4ba3-9c57-780e232bfbba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mu: 6.2117740882059715\n",
            "sigma: 2.48647227660039\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "data = [4, 5, 7, 8, 8, 9, 10, 5, 2, 3, 5, 4, 8, 9]\n",
        "\n",
        "# add your code here\n",
        "\n",
        "def neg_log_likelihood(data, mu, sigma):\n",
        "    n = len(data)\n",
        "    ll = -n/2 * np.log(2*np.pi*sigma**2) - 1/(2*sigma**2) * np.sum((data - mu)**2)\n",
        "    return -ll\n",
        "\n",
        "def compute_gradients(data, mu, sigma):\n",
        "    data = np.array(data)\n",
        "    n = len(data)\n",
        "    d_mu = -1/sigma**2 * np.sum(data - mu)\n",
        "    d_sigma = n/(2*sigma**2) - 1/(2*sigma**4) * np.sum((data - mu)**2)\n",
        "    return d_mu, d_sigma\n",
        "\n",
        "'''\n",
        "here gradient descent is being used to estimate the paramters mu and sigma\n",
        "What the algorithm is doing is minimizing the cost function (nll) \n",
        "'''\n",
        "def grad_descent(data):\n",
        "    mu, sigma = 0, 1\n",
        "    n_epochs = 4000\n",
        "    eta = 0.001\n",
        "    for epoch in range(n_epochs):\n",
        "        d_mu, d_sigma = compute_gradients(data, mu, sigma)\n",
        "        mu -= eta * d_mu\n",
        "        sigma -= eta * d_sigma\n",
        "    return mu, sigma\n",
        "\n",
        "\n",
        "mu, sigma = grad_descent(data)\n",
        "\n",
        "print(\"mu:\", mu)\n",
        "print(\"sigma:\", sigma)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RuYvxCzORSu"
      },
      "source": [
        "## MLE of a conditional Gaussian $p_{model}(y|x,w)$\n",
        "\n",
        "You are given a problem that involves the relationship between $x$ and $y$. Estimate the parameters of a $p_{model}$ that fit the dataset (x,y) shown below.   You are free to use any Gradient-based optimization method you like.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOs4EvG8ORSu",
        "outputId": "d2c4b362-6159-4efb-df83-562e6c0d3ef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mu: 18.72591586115306\n",
            "sigma: 10.582351326996752\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([8, 16, 22, 33, 50, 51])\n",
        "y = np.array([5, 20, 14, 32, 42, 58])\n",
        "\n",
        "# add your code here\n",
        "def neg_log_likelihood(x, y, mu, sigma):\n",
        "    n = len(x) + len(y)\n",
        "    ll = (-n/2 * np.log(2*np.pi*sigma**2) - 1/(2*sigma**2) * np.sum((x - mu)**2)) + (-n/2 * np.log(2*np.pi*sigma**2) - 1/(2*sigma**2) * np.sum((y - mu)**2))\n",
        "    return -ll\n",
        "\n",
        "def compute_gradients(x, y, mu, sigma):\n",
        "    x = np.array(x)\n",
        "    y = np.array(y)\n",
        "    n = len(x) + len(y)\n",
        "    d_mu = (-1/sigma**2 * np.sum(x - mu)) + (-1/sigma**2 * np.sum(y - mu))\n",
        "    d_sigma = (n/(2*sigma**2) - 1/(2*sigma**4) * np.sum((x - mu)**2)) + (n/(2*sigma**2) - 1/(2*sigma**4) * np.sum((y - mu)**2))\n",
        "    return d_mu, d_sigma\n",
        "\n",
        "def grad_descent(x, y):\n",
        "    mu, sigma = 0, 1\n",
        "    n_epochs = 8000\n",
        "    eta = 0.001\n",
        "    for epoch in range(n_epochs):\n",
        "        d_mu, d_sigma = compute_gradients(x, y, mu, sigma)\n",
        "        mu -= eta * d_mu\n",
        "        sigma -= eta * d_sigma\n",
        "    return mu, sigma\n",
        "\n",
        "\n",
        "mu, sigma = grad_descent(x, y)\n",
        "\n",
        "print(\"mu:\", mu)\n",
        "print(\"sigma:\", sigma)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "7d6993cb2f9ce9a59d5d7380609d9cb5192a9dedd2735a011418ad9e827eb538"
      }
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}